---
title: "Identify Genomic Instability CSV files"
format: 
  docx:
    reference-doc: north_west_glh_document_template.docx
fig-align: "left"
fig-wdith: 6
---

```{r}
#| label: dna-db-connection
#| include: FALSE

source(here::here("functions/functions.R"))
source(here::here("scripts/connect_to_sql_server.R"))

```

# Find SeqOne genomic instability worksheets

```{r}
#| label: find-seqone-gi-worksheets
#| include: FALSE

all_worksheets <- dna_db_worksheets |> 
  select(pcrid, date, description) |> 
  collect() |> 
  mutate(ws = paste0("WS", pcrid))

stopifnot(nrow(all_worksheets) > 0)

seqone_ws_regex <- "seqone|seq\\sone|seq_one|SSXT\\ssWGS\\sHRD"

gi_ws_info <- all_worksheets |> 
  filter(grepl(pattern = seqone_ws_regex,
               x = description,
               ignore.case = TRUE))

stopifnot(nrow(gi_ws_info) > 0)

```

The first step of the pipeline is to identify all the SeqOne genomic instability worksheets.
This is done via a connection to the DNA Database mirror which is hosted on a Microsoft SQL server.
The script checks the "description" column of the worksheet table in DNA Database.
The "description" column is free-type, so there are many different ways in which SeqOne worksheets have been described.
By using regular expressions (ways to find specific patterns of letters in the description column) this script has found `r nrow(gi_ws_info)` SeqOne worksheets ranging from
`r format(min(gi_ws_info$date), "%B %Y")` to
`r format(max(gi_ws_info$date), "%B %Y")` 
(WS`r min(gi_ws_info$pcrid)` to WS`r max(gi_ws_info$pcrid)`).
There are `r length(unique(gi_ws_info$description))` different ways in which SeqOne worksheets have been identified, listed below:

```{r}
#| label: tbl-gi-ws-descriptions
#| echo: FALSE

knitr::kable(gi_ws_info |> 
               filter(!duplicated(description)) |> 
               select(description) |> 
               arrange(description))

```

# Find SeqOne genomic instability csv files

```{r}
#| label: find-csvs-on-s-drive
#| include: FALSE

gi_ws_list <- list(gi_ws_info$ws)

gi_ws_filepaths <- gi_ws_list |> 
  map(\(gi_ws_list) find_ws_filepaths(worksheet = gi_ws_list,
                                      pattern = "hrd-results.*csv")) |> 
  flatten()

filename_regex <- regex(
  r"[
  /           # The last forward slash in the filepath
  ([^/]*      # Variable name before hrd-results but must not include forward slash
  hrd-results # All filenames contain hrd-results somewhere in the string
  .*          # Variable name after hrd-results
  \.csv)      # File type
  ]",
  comments = TRUE
)

gi_filepath_df <- tibble(
  filepath = unlist(gi_ws_filepaths)) |> 
  mutate(filename = str_extract(string = filepath,
                                pattern = filename_regex,
                                group = 1),
         filename_length = str_length(filename))

stopifnot(anyNA(gi_filepath_df$filename) == FALSE)
stopifnot(max(gi_filepath_df$filename_length) < 50)

```

The next step is to use the list of SeqOne GI worksheets to identify csv (comma separated value) files on the shared S drive.
These files will be saved within individual worksheet folders in the "WorksheetAnalysedData" folder at this file location:
`r config::get("ws_folderpath")`.

However there are two issues:

- Issue 1: the same file may be saved in multiple folders, so filepath cannot be used as a unique identifier

- Issue 2: the folder structure is not consistent. Some files are saved in a
folder called the worksheet name, others are in sub-folders. This makes parsing filenames from filepaths with regex more complicated.

In total, the script has identified 
`r nrow(gi_filepath_df)` different csv files.

# Identify SeqOne csv files that have not already been collated

```{r}
#| label: identify-new-seqone-files
#| include: FALSE

initial_folder <-  paste0(config::get("data_folderpath"), 
                          "01_initial/")

gi_csv_archive_folder <- paste0(initial_folder,
                                "gi_csv_archive")

gi_csv_new_folder <- paste0(initial_folder,
                            "gi_csv_new")

if(length(list.files(gi_csv_new_folder)) != 0){
  stop("New data folder is not empty")
} else {
  message("New data folder is empty")
}

gi_archive_file_df <- tibble(
  filename = list.files(gi_csv_archive_folder,
                        full.names = FALSE))

gi_new_filepath_df <- gi_filepath_df |> 
  filter(!filename %in% gi_archive_file_df$filename)

if(nrow(gi_new_filepath_df) == 0) {
  message("No new files identified.")
}
if(nrow(gi_new_filepath_df) > 0) {
  
  message(paste0(length(gi_new_filepath_df$filepath),
                 " new files identified"))
  
  gi_filepaths_to_copy <- gi_new_filepath_df$filepath
  
  message("Copying csv files to directory")
  
  file.copy(from = gi_filepaths_to_copy,
            to = gi_csv_new_folder)
  
  quarto::quarto_render(here::here("scripts/gi_csv_collate.qmd"))
} 

```

The script has identified 
`r length(gi_new_filepath_df$filepath)`
new files which need to be collated.
